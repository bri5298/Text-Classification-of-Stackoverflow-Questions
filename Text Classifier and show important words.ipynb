{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da78cf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BrielleJohnston\\Documents\\Python\\personnal-projects\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "if os.getcwd().endswith('notebooks'):\n",
    "    os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370e62ad",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe2f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger') \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdbcd9c",
   "metadata": {},
   "source": [
    "## Functions and Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0948df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(contexts:list) -> str:\n",
    "    \"\"\"\n",
    "        contexts: a list of strings\n",
    "        \n",
    "        return: cleaned list of strings\n",
    "    \"\"\"\n",
    "    clean_text = []\n",
    "    for context in contexts:\n",
    "        text = context.lower() # lowercase text\n",
    "        text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "        text = BAD_SYMBOLS_RE.sub('', text) # delete bad characters from text aka the one excluded from BAD_SYMBOLS_RE regex\n",
    "        text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "        clean_text.append(text)\n",
    "    return clean_text\n",
    "\n",
    "\n",
    "# Class to get the prediction and most important words\n",
    "class Results:\n",
    "    \"\"\"\n",
    "    \n",
    "    A Class to represent the results from a single prediction.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    string : str\n",
    "        the string of the context we want to predict.\n",
    "    model : MultinomialNB()\n",
    "        the Naive Bayes ml model we are using to make the prediction.\n",
    "    n_important_words : int\n",
    "        the number of important words we want to see.\n",
    "    \n",
    "    Functions\n",
    "    -------\n",
    "    get_prediction(self) -> str:\n",
    "        Returns the prediction for the string.\n",
    "    get_important_words(self) -> list:\n",
    "        Returns the words that contributed the most to the prediction.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, string, model, n_important_words):\n",
    "        self.string = string\n",
    "        self.model = model\n",
    "        self.n_important_words = n_important_words\n",
    "        self.prediction = self.get_prediction()\n",
    "        self.important_words = self.get_important_words()\n",
    "  \n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"The text is ====> \\n{self.string} \\n\\nPrediction is ===> {self.prediction}\"\n",
    "\n",
    "\n",
    "    def get_prediction(self):\n",
    "        self.string_list = []\n",
    "        self.string_list.append(self.string)\n",
    "        self.string_trnsfm = clean_text(self.string_list)\n",
    "        self.string_trnsfm = vectorizer.transform(self.string_list)\n",
    "        self.prediction = self.model.predict(self.string_trnsfm)[0]\n",
    "        return self.prediction\n",
    "\n",
    "\n",
    "    def get_important_words(self):\n",
    "        map_word_to_rank = {}\n",
    "        # Cleaning the input string\n",
    "        string_list = [string]\n",
    "        clean_string = clean_text(string_list)[0]\n",
    "        clean_string = re.sub('\\d', ' ', clean_string)\n",
    "        words = clean_string.split()\n",
    "        # Getting the most important words per label\n",
    "        map_class_to_coef = dict(zip(self.model.classes_, self.model.feature_log_prob_))\n",
    "        # sort the coefficients and use the index\n",
    "        class_coeffs_sorted = map_class_to_coef[self.prediction].argsort()[::-1]\n",
    "        # how important is each word in the classification\n",
    "        map_order_to_words = dict(\n",
    "            zip(np.take(vectorizer.get_feature_names_out(), class_coeffs_sorted), \n",
    "                range(len(np.take(vectorizer.get_feature_names_out(), class_coeffs_sorted)))\n",
    "               )\n",
    "        )\n",
    "        for word in words: # rank the words in the string by order of importance\n",
    "            map_word_to_rank[word] = map_order_to_words.get(word, 99999999)\n",
    "        important_words = sorted(map_word_to_rank, key=map_word_to_rank.get, reverse=False)[:self.n_important_words] \n",
    "        return important_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682cee94",
   "metadata": {},
   "source": [
    "## Import the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c2a66bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>java</td>\n",
       "      <td>java collections sort() equal objects  i want ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iphone</td>\n",
       "      <td>memory is increasing in bytes when the image i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>java</td>\n",
       "      <td>what is wrong with my method   i just wanted t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sql</td>\n",
       "      <td>are parameterized queries sql standards   are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>html</td>\n",
       "      <td>how do i center my webpage   how do i center m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                               post\n",
       "0    java  java collections sort() equal objects  i want ...\n",
       "1  iphone  memory is increasing in bytes when the image i...\n",
       "2    java  what is wrong with my method   i just wanted t...\n",
       "3     sql  are parameterized queries sql standards   are ...\n",
       "4    html  how do i center my webpage   how do i center m..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join('data', 'stackoverflow_qs_for_classification.csv')).sample(frac=1).reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb2863e",
   "metadata": {},
   "source": [
    "### Create Train and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdeb8e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc[:7500]\n",
    "df_test = df.loc[7501:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecec82a",
   "metadata": {},
   "source": [
    "## Clean and Tokenize the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610e6eb7",
   "metadata": {},
   "source": [
    "### Make lowercase, remove stopwords and special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bde6b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['expected identifier working web browser app moment stuck error expected identifier know code error shown precode error nsurl url nsurl urlwithstringurlstring nsurlrequest urlrequest nsurlrequest requestwithurlurl selfwebview loadrequesturlrequest code pre help appreciated update know code supposed give whole code viewcontrollerm file precode#import viewcontrollerh interface viewcontroller property weak nonatomic iboutlet uiwebview webview property weak nonatomic iboutlet uibarbuttonitem back property weak nonatomic iboutlet uibarbuttonitem refresh property weak nonatomic iboutlet uibarbuttonitem stop property weak nonatomic iboutlet uibarbuttonitem forward void loadrequestfromstring nsstring urlstring errorexpected identifier nsurl url nsurl urlwithstringurlstring nsurlrequest urlrequest nsurlrequest requestwithurlurl selfwebview loadrequesturlrequest end implementation viewcontroller warning sayingmethod definition loadrequestfromstring found void viewdidload super viewdidload enter code hereadditional setup loading view typically nib self loadrequestfromstring http wwwapplecom startpage void didreceivememorywarning super didreceivememorywarning dispose resources recreated end code pre',\n",
       " 'make default value short element 0 instead null program creates lists needs assigned values 0 running fine codeint humpty_dumpty new int 20 code optimize size lists set codeshort code program breaking takes zero inputs codeshort humpty_dumpty new short 20 code making default value codenull code way set default zero without iterate entire list via loop wondering way make behavior similar int',\n",
       " 'move block code method efficiency purposes think conceptual misunderstanding would appreciate explanation within class block code repeating 3 times working perfectly try make things efficient took made method within class follows precode void dateup nslog dateup uiview beginanimations datepicker contextnil uiview setanimationduration05 datepickertransform cgaffinetransformmaketranslation 0 310 uiview commitanimations code pre code originally put precode self dateup code pre put following h precode void dateup code pre build get warning precodeline location detailpopupviewm165 warning method definition dateup found code pre crash console btw nslog statement appear console precode terminating app due uncaught exception nsinvalidargumentexception reason detailpopupview dateup unrecognized selector sent instance 0x3d33ef0 code pre help appreciated one thing notice console message dateup colon parameter expected whereas simplest solution put code back repeating 3x like know wrong thanks']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts = df_train['post'].tolist()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "STOPWORDS = set(stopwords)\n",
    "REPLACE_BY_SPACE_RE = re.compile(r'[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile(r'[^0-9a-z #+_]')\n",
    "clean_contexts = clean_text(contexts=contexts)\n",
    "clean_contexts[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe690ef",
   "metadata": {},
   "source": [
    "### Tfidf Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c46ead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 7501, n_features: 70287\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(clean_contexts)\n",
    "print(\"n_samples: %d, n_features: %d\" % vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fab6817",
   "metadata": {},
   "source": [
    "## Split into y_train and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddf43583",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectors\n",
    "y_train = df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c395f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(df_test['post'].to_list())\n",
    "y_test = df_test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d6d448",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230c3e5a",
   "metadata": {},
   "source": [
    "## Create Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2baf0409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a67360",
   "metadata": {},
   "source": [
    "### View Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "121e03d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9059623849539816\n"
     ]
    }
   ],
   "source": [
    "predictions = naive_bayes.predict(X_test)\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af7d62b",
   "metadata": {},
   "source": [
    "### Take a random test context and see the prediction and important words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f0648b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actual label is:  sql \n",
      "\n",
      "The text is ====> \n",
      "sql: set value with condition  i have some problem  there are two tables  they communicate with the value id. now i will set the value from column <strong>a</strong> in table <strong>a</strong> with the value  nein   but only if the value of the column <strong>b</strong> in table <strong>b</strong> is  0  and  if a.id = b.id.    how can i do that  thanks \n",
      "\n",
      "Prediction is ===> sql\n",
      "\n",
      "Words that have the most importance in the prediction: ['table', 'sql', 'column', 'tables', 'id']\n"
     ]
    }
   ],
   "source": [
    "testing_row = df_test.sample(n=1)\n",
    "string = testing_row['post'].values[0]\n",
    "results = Results(string, model=naive_bayes, n_important_words=5)\n",
    "print('\\nActual label is: ', testing_row['label'].values[0], '\\n')\n",
    "print(results)\n",
    "print(f'\\nWords that have the most importance in the prediction: {results.get_important_words()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb78c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
